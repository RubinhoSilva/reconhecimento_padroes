{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from math import prod\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validação dos dados EOG\n",
    "\n",
    "Neste notebook está incluído os seguintes passos:\n",
    "- Aplicação de características;\n",
    "- Criação do vetor de características;\n",
    "- Normalização de dados;\n",
    "- Seleção de características;\n",
    "- Classificação dos dados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uma característica é uma propriedade individual mensurável ou característica de um fenômeno que está sendo observado. Em nosso caso de EOG, uma característica pode ser extraída no domínio do tempo ou no domínio da frequência. As características a seguir foram retiradas do artigo *EMG Feature Extraction for Tolerance of White Gaussian Noise* \\[1\\]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio do tempo\n",
    "\n",
    "1. Willison Amplitude (WAMP)\n",
    "\n",
    "    > $ \\sum_{i=1}^{N-1}f(|x_i - x_{i+1}|) $\n",
    "    \n",
    "    > $ f(x) = \\begin{cases} 1 & \\text{if } x \\gt threshold \\\\ 0 & \\text{otherwise} \\end{cases} $\n",
    "\n",
    "2. Variance of EMG (VAR)\n",
    "\n",
    "    > $ \\frac{1}{N-1}\\sum_{i=1}^{N}x_i^2 $\n",
    "\n",
    "3. Root Mean Square (RMS)\n",
    "\n",
    "    > $ \\sqrt{\\frac{1}{N}\\sum_{i=1}^{N}|x_i|^2} $\n",
    "\n",
    "4. Waveform Length (WL)\n",
    "    \n",
    "    > $ \\sum_{i=1}^{N-1}|x_{i+1} - x_i| $\n",
    "\n",
    "5. Zero Crossing (ZC)\n",
    "\n",
    "    > $ \\sum_{i=1}^{N}sgn(x_i) $\n",
    "    \n",
    "    > $ sgn(x) = \\begin{cases} 1 & \\text{if } x_i * x_{i+1} \\leq 0 \\\\ 0 & \\text{otherwise} \\end{cases} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Domínio da frequência\n",
    "\n",
    "1. Median Frequency (FMD)\n",
    "\n",
    "    > $ \\frac{1}{2}\\sum_{j=1}^{M}PSD_j $\n",
    "\n",
    "2. Mean Frequency (FMN)\n",
    "\n",
    "    > $\\sum_{j=1}^{M}f_j PSD_j / \\sum_{j=1}^{M}PSD_j$\n",
    "    \n",
    "    > $ f_j = j * SampleRate / 2 * M $\n",
    "\n",
    "3. Modified Median Frequency (MMDF)\n",
    "\n",
    "    > $ \\frac{1}{2}\\sum_{j=1}^{M}A_j $\n",
    "    \n",
    "    > $ A_j = Amplitude\\ do\\ espectro\\ j $\n",
    "\n",
    "4. Modified Frequency Mean (MMNF)\n",
    "\n",
    "    > $ \\sum_{j=1}^{M}f_jAj / \\sum_{j=1}^{M}Aj $\n",
    "\n",
    "\n",
    "\\[1\\] Phinyomark, Angkoon & Limsakul, Chusak & Phukpattaranont, P.. (2008). EMG Feature Extraction for Tolerance of White Gaussian Noise.\n",
    "[Disponível neste link](https://www.researchgate.net/publication/263765853_EMG_Feature_Extraction_for_Tolerance_of_White_Gaussian_Noise)\n",
    "\n",
    "**Tarefa 1**: Descrever as características de acordo com o artigo citado e outros disponíveis relacionados. O que está querendo \"ser visto\" em cada característica? Qual é o significado matemático de cada uma delas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aplicando as características\n",
    "\n",
    "É necessário implementar as características, geralmente em formato de funções ou métodos, para que seja possível aplicar tais funções aos dados de entrada e obter as características resultantes. A seguir temos a implementação das características `VAR` & `RMS` (domínio do tempo) e `FDM` & `MMDF` (domínio da frequência)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# funções auxiliares\n",
    "def PSD(w):\n",
    "    ''' definição da função PSD para o sinal no domínio da frequência '''\n",
    "    return np.abs(w) ** 2\n",
    "\n",
    "def sign(x):\n",
    "    return x[:-1] * x[1:]\n",
    "\n",
    "# funções de extração de características\n",
    "def var(x):\n",
    "    return np.sum(x ** 2, axis=-1) / (np.prod(x.shape) - 1)\n",
    "\n",
    "def rms(x):\n",
    "    return np.sqrt(np.sum(np.abs(x) ** 2, axis=-1) / (np.prod(x.shape) - 1))\n",
    "\n",
    "def fmd(w):\n",
    "    return np.sum(PSD(w), axis=-1) / 2\n",
    "\n",
    "def mmdf(w):\n",
    "    return np.sum(np.abs(w), axis=-1) / 2\n",
    "\n",
    "def wl(x):\n",
    "    return np.sum(np.abs(np.diff(x)), axis=-1)\n",
    "\n",
    "def zc(x):\n",
    "    return np.sum(sign(x) <= 0, axis=-1)\n",
    "\n",
    "def wamp(x, threshold):\n",
    "    differences = np.diff(x)\n",
    "    crossings = np.where(np.abs(differences) > threshold, 1, 0)\n",
    "    return np.sum(crossings)\n",
    "\n",
    "def fmn(x):\n",
    "    return np.sum(PSD(x))\n",
    "\n",
    "def mmnf(x):\n",
    "    return np.sum(PSD(x)) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tarefa 2**: Implemente todas as características apresentadas neste tutorial em formato de funções. Sinta-se livre também para buscar e implementar características além das apresentadas, citando as fontes de tais características.\n",
    "\n",
    "\n",
    "#### Vetor de características\n",
    "\n",
    "Ao final da implementação e seleção das características, deve ser escolhida as características e então teremos um vetor com todas elas implementadas.\n",
    "\n",
    "O vetor de características estará organizado da seguinte forma (exemplo p/ VAR, RMS, RDM e MMDF):\n",
    "\n",
    "| ID sample | VAR1 | RMS1 | FMD1 | MMDF1 | VAR2 | RMS2 | FMD2 | MMDF2 | Classe |\n",
    "|:---------:|:----:|:----:|:----:|:-----:|------|------|------|-------|:------:|\n",
    "|     1     |  v1  |  v1  |  v1  |   v1  | v1   | v1   | v1   | v1    |    0   |\n",
    "|     2     |  v2  |  v2  |  v2  |   v2  | v2   | v2   | v2   | v2    |    0   |\n",
    "|    ...    |  ... |  ... |  ... |  ...  | ...  | ...  | ...  | ...   |   ...  |\n",
    "|     N     |  vN  |  vN  |  vN  |   vN  | vN   | vN   | vN   | vN    |    7   |\n",
    "\n",
    "#### Implementação do vetor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# carregando dados do \"prepare.ipynb\"\n",
    "\n",
    "todos_time = np.load(\"datasets/todos_time.npy\")\n",
    "todos_frequencia = np.load(\"datasets/todos_frequencia.npy\")\n",
    "\n",
    "gabi_time = np.load(\"datasets/gabi_time.npy\")\n",
    "gabi_frequencia = np.load(\"datasets/gabi_frequencia.npy\")\n",
    "\n",
    "jesse_time = np.load(\"datasets/jesse_time.npy\")\n",
    "jesse_frequencia = np.load(\"datasets/jesse_frequencia.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Todos participantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos vetores originais: (2, 28, 33, 2, 64) (2, 28, 33, 2, 33)\n",
      "Shape dos vetores mudança 1: (56, 33, 2, 64) (56, 33, 2, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((),\n",
       " (56, 33, 2),\n",
       " (56, 33, 2),\n",
       " (56, 33, 2),\n",
       " (55, 33, 2),\n",
       " (56, 33, 2),\n",
       " (),\n",
       " (56, 33, 2),\n",
       " ())"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape dos vetores originais:\", todos_time.shape, todos_frequencia.shape)\n",
    "\n",
    "# mudando o de todos para 56, 33, 2, 64 e 56, 33, 2, 33\n",
    "todos_time = todos_time.reshape((-1, 33, 2, 64))\n",
    "todos_frequencia = todos_frequencia.reshape((-1, 33, 2, 33))\n",
    "\n",
    "print(\"Shape dos vetores mudança 1:\", todos_time.shape, todos_frequencia.shape)\n",
    "\n",
    "\n",
    "# aplicando características\n",
    "data_var = var(todos_time)\n",
    "data_rms = rms(todos_time)\n",
    "data_wl = wl(todos_time)\n",
    "data_zc = zc(todos_time)\n",
    "\n",
    "time_median = np.median(todos_time)\n",
    "data_wamp = wamp(todos_time, time_median) # threshold ser a mediana dos valores totais\n",
    "\n",
    "data_fmd = fmd(todos_frequencia)\n",
    "data_fmn = fmn(todos_frequencia)\n",
    "data_mmdf = mmdf(todos_frequencia)\n",
    "data_mmnf = mmnf(todos_frequencia)\n",
    "\n",
    "data_wamp.shape, data_var.shape, data_rms.shape, data_wl.shape, data_zc.shape, data_fmd.shape, data_fmn.shape, data_mmdf.shape, data_mmnf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 56, 33, 2)\n",
      "(33, 56, 5, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1848, 10)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# União do vetor de características inicial\n",
    "features = np.array([data_var, data_rms, data_wl, data_fmd, data_mmdf])\n",
    "print(features.shape)\n",
    "\n",
    "# organização das dimensões\n",
    "features = features.transpose(2, 1, 0, 3)\n",
    "print(features.shape)\n",
    "\n",
    "# criar vetor de características definitivo\n",
    "features = features.reshape(features.shape[0] * features.shape[1],\n",
    "                            features.shape[2] * features.shape[3])\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aplicando normalização\n",
    "X_normalizado = StandardScaler().fit_transform(features)\n",
    "\n",
    "# código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 2, 3, 3, 1, 0, 3, 0, 0, 1, 2, 3, 2, 1, 0, 2, 1, 3, 1, 0, 1, 2, 0, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1848,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtendo labels\n",
    "\n",
    "labels_str = ['dir', 'esq', 'cima', 'baixo', 'cima', 'baixo',\n",
    "'baixo', 'esq', 'dir', 'baixo', 'dir', 'dir', 'esq', 'cima',\n",
    "'baixo', 'cima', 'esq', 'dir', 'cima', 'esq', 'baixo', 'esq',\n",
    "'dir', 'esq', 'cima', 'dir', 'cima', 'baixo']\n",
    "\n",
    "# transformando para numérico\n",
    "lab_dict = {'dir': 0, 'esq': 1, 'cima': 2, 'baixo': 3}\n",
    "labels_num = [lab_dict[item] for item in labels_str]\n",
    "\n",
    "print(labels_num)\n",
    "\n",
    "# criação do vetor de labels final\n",
    "y = np.repeat(labels_num, int(features.shape[0] / len(labels_num)))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1848, 10), (1848,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplicando seleção de características\n",
    "X_normalizado.shape, y.shape\n",
    "# código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1848, 10)\n"
     ]
    }
   ],
   "source": [
    "# aplicando seleção de características\n",
    "rfe = RFECV(SVC(kernel=\"linear\"), step=0.000001, min_features_to_select=1, cv=10)\n",
    "X_final = rfe.fit_transform(X_normalizado, y)\n",
    "print(X_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy svm 0.8333333333333334\n",
      "f1_score svm 0.8222222222222223\n",
      "accuracy random forest 0.3333333333333333\n",
      "f1_score random forest 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# aplicando a classificação\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.003, random_state=42)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)  \n",
    "\n",
    "print(\"accuracy svm\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score svm\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "\n",
    "# Criando e treinando o modelo RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "print(\"accuracy random forest\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score random forest\", f1_score(y_test, y_pred, average=\"weighted\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1848, 6)\n"
     ]
    }
   ],
   "source": [
    "rfe = RFECV(RandomForestClassifier(n_estimators=100, random_state=42), step=0.000001, min_features_to_select=1, cv=3, scoring='accuracy')\n",
    "X_final = rfe.fit_transform(X_normalizado, y)\n",
    "print(X_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy svm 0.3207207207207207\n",
      "f1_score svm 0.292411109157848\n",
      "accuracy random forest 0.42342342342342343\n",
      "f1_score random forest 0.4266260128542383\n"
     ]
    }
   ],
   "source": [
    "# aplicando a classificação\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)  \n",
    "\n",
    "print(\"accuracy svm\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score svm\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "\n",
    "# Criando e treinando o modelo RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "print(\"accuracy random forest\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score random forest\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Participante Jesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos vetores originais: (2, 28, 33, 2, 64) (2, 28, 33, 2, 33)\n",
      "Shape dos vetores mudança 1: (2, 28, 33, 2, 64) (2, 28, 33, 2, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((),\n",
       " (28, 33, 2),\n",
       " (28, 33, 2),\n",
       " (28, 33, 2),\n",
       " (27, 33, 2),\n",
       " (28, 33, 2),\n",
       " (),\n",
       " (28, 33, 2),\n",
       " ())"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape dos vetores originais:\", todos_time.shape, todos_frequencia.shape)\n",
    "\n",
    "# mudando o de todos para 56, 33, 2, 64 e 56, 33, 2, 33\n",
    "jesse_time = jesse_time.reshape((-1, 33, 2, 64))\n",
    "jesse_frequencia = jesse_frequencia.reshape((-1, 33, 2, 33))\n",
    "\n",
    "print(\"Shape dos vetores mudança 1:\", todos_time.shape, todos_frequencia.shape)\n",
    "\n",
    "\n",
    "# aplicando características\n",
    "data_var = var(jesse_time)\n",
    "data_rms = rms(jesse_time)\n",
    "data_wl = wl(jesse_time)\n",
    "data_zc = zc(jesse_time)\n",
    "\n",
    "time_median = np.median(jesse_time)\n",
    "data_wamp = wamp(jesse_time, time_median) # threshold ser a mediana dos valores totais\n",
    "\n",
    "data_fmd = fmd(jesse_frequencia)\n",
    "data_fmn = fmn(jesse_frequencia)\n",
    "data_mmdf = mmdf(jesse_frequencia)\n",
    "data_mmnf = mmnf(jesse_frequencia)\n",
    "\n",
    "data_wamp.shape, data_var.shape, data_rms.shape, data_wl.shape, data_zc.shape, data_fmd.shape, data_fmn.shape, data_mmdf.shape, data_mmnf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 28, 33, 2)\n",
      "(33, 28, 5, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# União do vetor de características inicial\n",
    "features = np.array([data_var, data_rms, data_wl, data_fmd, data_mmdf])\n",
    "print(features.shape)\n",
    "\n",
    "# organização das dimensões\n",
    "features = features.transpose(2, 1, 0, 3)\n",
    "print(features.shape)\n",
    "\n",
    "# criar vetor de características definitivo\n",
    "features = features.reshape(features.shape[0] * features.shape[1],\n",
    "                            features.shape[2] * features.shape[3])\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aplicando normalização\n",
    "X_normalizado = StandardScaler().fit_transform(features)\n",
    "\n",
    "# código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 2, 3, 3, 1, 0, 3, 0, 0, 1, 2, 3, 2, 1, 0, 2, 1, 3, 1, 0, 1, 2, 0, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtendo labels\n",
    "\n",
    "labels_str = ['dir', 'esq', 'cima', 'baixo', 'cima', 'baixo',\n",
    "'baixo', 'esq', 'dir', 'baixo', 'dir', 'dir', 'esq', 'cima',\n",
    "'baixo', 'cima', 'esq', 'dir', 'cima', 'esq', 'baixo', 'esq',\n",
    "'dir', 'esq', 'cima', 'dir', 'cima', 'baixo']\n",
    "\n",
    "# transformando para numérico\n",
    "lab_dict = {'dir': 0, 'esq': 1, 'cima': 2, 'baixo': 3}\n",
    "labels_num = [lab_dict[item] for item in labels_str]\n",
    "\n",
    "print(labels_num)\n",
    "\n",
    "# criação do vetor de labels final\n",
    "y = np.repeat(labels_num, int(features.shape[0] / len(labels_num)))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((924, 10), (924,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplicando seleção de características\n",
    "X_normalizado.shape, y.shape\n",
    "# código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 6)\n"
     ]
    }
   ],
   "source": [
    "# aplicando seleção de características\n",
    "rfe = RFECV(SVC(kernel=\"linear\"), step=0.000001, min_features_to_select=1, cv=5)\n",
    "X_final = rfe.fit_transform(X_normalizado, y)\n",
    "print(X_final.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy svm 0.35251798561151076\n",
      "f1_score svm 0.31506707284189284\n",
      "accuracy random forest 0.381294964028777\n",
      "f1_score random forest 0.38414743956733766\n"
     ]
    }
   ],
   "source": [
    "# aplicando a classificação\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)  \n",
    "\n",
    "print(\"accuracy svm\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score svm\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "\n",
    "# Criando e treinando o modelo RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "print(\"accuracy random forest\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score random forest\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 10)\n"
     ]
    }
   ],
   "source": [
    "rfe = RFECV(RandomForestClassifier(n_estimators=100, random_state=42), step=0.000001, min_features_to_select=1, cv=10, scoring='accuracy')\n",
    "X_final = rfe.fit_transform(X_normalizado, y)\n",
    "print(X_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy svm 0.35251798561151076\n",
      "f1_score svm 0.3230395503776799\n",
      "accuracy random forest 0.44244604316546765\n",
      "f1_score random forest 0.44436532705445353\n"
     ]
    }
   ],
   "source": [
    "# aplicando a classificação\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)  \n",
    "\n",
    "print(\"accuracy svm\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score svm\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "\n",
    "# Criando e treinando o modelo RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "print(\"accuracy random forest\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score random forest\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Participante Gabi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape dos vetores originais: (56, 33, 2, 64) (56, 33, 2, 33)\n",
      "Shape dos vetores mudança 1: (56, 33, 2, 64) (56, 33, 2, 33)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((),\n",
       " (28, 33, 2),\n",
       " (28, 33, 2),\n",
       " (28, 33, 2),\n",
       " (27, 33, 2),\n",
       " (28, 33, 2),\n",
       " (),\n",
       " (28, 33, 2),\n",
       " ())"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Shape dos vetores originais:\", todos_time.shape, todos_frequencia.shape)\n",
    "\n",
    "# mudando o de todos para 56, 33, 2, 64 e 56, 33, 2, 33\n",
    "gabi_time = gabi_time.reshape((-1, 33, 2, 64))\n",
    "gabi_frequencia = gabi_frequencia.reshape((-1, 33, 2, 33))\n",
    "\n",
    "print(\"Shape dos vetores mudança 1:\", todos_time.shape, todos_frequencia.shape)\n",
    "\n",
    "\n",
    "# aplicando características\n",
    "data_var = var(gabi_time)\n",
    "data_rms = rms(gabi_time)\n",
    "data_wl = wl(gabi_time)\n",
    "data_zc = zc(gabi_time)\n",
    "\n",
    "time_median = np.median(gabi_time)\n",
    "data_wamp = wamp(gabi_time, time_median) # threshold ser a mediana dos valores totais\n",
    "\n",
    "data_fmd = fmd(gabi_frequencia)\n",
    "data_fmn = fmn(gabi_frequencia)\n",
    "data_mmdf = mmdf(gabi_frequencia)\n",
    "data_mmnf = mmnf(gabi_frequencia)\n",
    "\n",
    "data_wamp.shape, data_var.shape, data_rms.shape, data_wl.shape, data_zc.shape, data_fmd.shape, data_fmn.shape, data_mmdf.shape, data_mmnf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 28, 33, 2)\n",
      "(33, 28, 5, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924, 10)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# União do vetor de características inicial\n",
    "features = np.array([data_var, data_rms, data_wl, data_fmd, data_mmdf])\n",
    "print(features.shape)\n",
    "\n",
    "# organização das dimensões\n",
    "features = features.transpose(2, 1, 0, 3)\n",
    "print(features.shape)\n",
    "\n",
    "# criar vetor de características definitivo\n",
    "features = features.reshape(features.shape[0] * features.shape[1],\n",
    "                            features.shape[2] * features.shape[3])\n",
    "\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 3*: Realização da normalização dos dados utilizando ferramentas já conhecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# aplicando normalização\n",
    "X_normalizado = StandardScaler().fit_transform(features)\n",
    "\n",
    "# código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 4*: Realização da seleção de características, utilizando ferramentas já conhecidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 2, 3, 3, 1, 0, 3, 0, 0, 1, 2, 3, 2, 1, 0, 2, 1, 3, 1, 0, 1, 2, 0, 2, 3]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(924,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# obtendo labels\n",
    "\n",
    "labels_str = ['dir', 'esq', 'cima', 'baixo', 'cima', 'baixo',\n",
    "'baixo', 'esq', 'dir', 'baixo', 'dir', 'dir', 'esq', 'cima',\n",
    "'baixo', 'cima', 'esq', 'dir', 'cima', 'esq', 'baixo', 'esq',\n",
    "'dir', 'esq', 'cima', 'dir', 'cima', 'baixo']\n",
    "\n",
    "# transformando para numérico\n",
    "lab_dict = {'dir': 0, 'esq': 1, 'cima': 2, 'baixo': 3}\n",
    "labels_num = [lab_dict[item] for item in labels_str]\n",
    "\n",
    "print(labels_num)\n",
    "\n",
    "# criação do vetor de labels final\n",
    "y = np.repeat(labels_num, int(features.shape[0] / len(labels_num)))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((924, 10), (924,))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# aplicando seleção de características\n",
    "X_normalizado.shape, y.shape\n",
    "# código"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 8)\n"
     ]
    }
   ],
   "source": [
    "# aplicando seleção de características\n",
    "rfe = RFECV(SVC(kernel=\"linear\"), step=0.000001, min_features_to_select=1, cv=6)\n",
    "X_final = rfe.fit_transform(X_normalizado, y)\n",
    "print(X_final.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação do vetor de *labels*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Tarefa 5*: Realização da classificação utilizando `SVM`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy svm 0.39568345323741005\n",
      "f1_score svm 0.3908264680203217\n",
      "accuracy random forest 0.381294964028777\n",
      "f1_score random forest 0.38405853182642513\n"
     ]
    }
   ],
   "source": [
    "# aplicando a classificação\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)  \n",
    "\n",
    "print(\"accuracy svm\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score svm\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "\n",
    "# Criando e treinando o modelo RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "print(\"accuracy random forest\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score random forest\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(924, 1)\n"
     ]
    }
   ],
   "source": [
    "rfe = RFECV(RandomForestClassifier(n_estimators=100, random_state=42), step=0.000001, min_features_to_select=1, cv=10, scoring='accuracy')\n",
    "X_final = rfe.fit_transform(X_normalizado, y)\n",
    "print(X_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy svm 0.2697841726618705\n",
      "f1_score svm 0.16522545257104776\n",
      "accuracy random forest 0.381294964028777\n",
      "f1_score random forest 0.3802140966558557\n"
     ]
    }
   ],
   "source": [
    "# aplicando a classificação\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_final, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "clf = SVC(kernel='linear', C=1, random_state=42, probability=True)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)  \n",
    "\n",
    "print(\"accuracy svm\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score svm\", f1_score(y_test, y_pred, average=\"weighted\"))\n",
    "\n",
    "# Criando e treinando o modelo RandomForestClassifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(x_train, y_train)\n",
    "\n",
    "# Fazendo previsões no conjunto de teste\n",
    "y_pred = rf_model.predict(x_test)\n",
    "\n",
    "print(\"accuracy random forest\", accuracy_score(y_test, y_pred))\n",
    "print(\"f1_score random forest\", f1_score(y_test, y_pred, average=\"weighted\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
